{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27a20032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from network import *\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8633cf38",
   "metadata": {},
   "source": [
    "# PRETRAIN MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95719638",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model =  Network().YOLO_v1_pretrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5324f71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " backbone (Sequential)       (None, 7, 7, 1024)        22439488  \n",
      "                                                                 \n",
      " average_pooling2d_2 (Averag  (None, 3, 3, 1024)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 20)                184340    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 20)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,623,828\n",
      "Trainable params: 22,605,652\n",
      "Non-trainable params: 18,176\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(base_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a56b1478",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_load = os.path.join('VOCdevkit_2007_trainval', \n",
    "                        'VOC2007', \n",
    "                        'JPEGImages', '000005.jpg')\n",
    "img = cv2.cvtColor(cv2.imread(img_load), cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "img = np.expand_dims(img, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "492da09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 18:11:36.215782: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 342ms/step\n"
     ]
    }
   ],
   "source": [
    "res = base_model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65e657fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 20)\n"
     ]
    }
   ],
   "source": [
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f07e4da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.save_weights('pretrain_model_weights.h5', save_format='h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccafa12d",
   "metadata": {},
   "source": [
    "# DETECT MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa3f1d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_v1 = Network().YOLO_v1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df980106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 448, 448, 3)]     0         \n",
      "                                                                 \n",
      " backbone (Sequential)       (None, 14, 14, 1024)      22439488  \n",
      "                                                                 \n",
      " neck (Sequential)           (None, 7, 7, 1024)        37769216  \n",
      "                                                                 \n",
      " fc_layers (Sequential)      (None, 1470)              211547582 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271,756,286\n",
      "Trainable params: 271,729,918\n",
      "Non-trainable params: 26,368\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(yolo_v1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "18090882",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_load = os.path.join('VOCdevkit_2007_trainval', \n",
    "                        'VOC2007', \n",
    "                        'JPEGImages', '000005.jpg')\n",
    "img = cv2.cvtColor(cv2.imread(img_load), cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (448, 448), interpolation=cv2.INTER_AREA)\n",
    "img = np.expand_dims(img, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "22905fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 18:19:39.792249: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x29b152ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 428ms/step\n"
     ]
    }
   ],
   "source": [
    "res = yolo_v1.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd5bea70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1470)\n"
     ]
    }
   ],
   "source": [
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d22f5f",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f84ff80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_v1.load_weights('pretrain_model_weights.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a509890",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
